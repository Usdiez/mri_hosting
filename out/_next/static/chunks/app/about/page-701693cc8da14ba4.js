(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[301],{2950:function(e,a,t){Promise.resolve().then(t.bind(t,2815))},2815:function(e,a,t){"use strict";t.r(a),t.d(a,{default:function(){return page}});var n=t(7437),s=t(9844),page=()=>{let e={hidden:{opacity:0},show:{opacity:1}};return(0,n.jsxs)(s.E.main,{variants:{hidden:{opacity:0},show:{opacity:1,transition:{staggerChildren:.3}}},initial:"hidden",animate:"show",className:"flex min-h-screen flex-row px-10",children:[(0,n.jsxs)(s.E.div,{variants:e,className:"grid grid-cols-2 gap-0 flex-1 mt-56 px-6",children:[(0,n.jsxs)(s.E.div,{variants:e,className:"flex flex-col items-center",children:[(0,n.jsx)("a",{href:"https://www.linkedin.com/in/wandbrandon/",target:"_blank",children:(0,n.jsx)("img",{src:"/_next/static/media/brandon.9b24a46a.jpeg",alt:"Image 3",className:"w-48 h-48 border-stone-200 border-x-4 border-y-4 object-cover"})}),(0,n.jsx)("a",{href:"https://www.linkedin.com/in/wandbrandon/",target:"_blank",className:"w-9/12 mt-2 text-center",children:"Brandon Wand"})]}),(0,n.jsxs)(s.E.div,{variants:e,className:"flex flex-col items-center",children:[(0,n.jsx)("a",{href:"https://nathanwand.com/",target:"_blank",children:(0,n.jsx)("img",{src:"/_next/static/media/nathan.8bf66f5b.png",alt:"Image 4",className:"w-48 h-48 border-stone-200 border-x-4 border-y-4 object-cover"})}),(0,n.jsx)("a",{href:"https://nathanwand.com/",target:"_blank",className:"w-9/12 mt-2 text-center",children:"Nathan Wand"})]}),(0,n.jsxs)(s.E.div,{variants:e,className:"flex flex-col items-center",children:[(0,n.jsx)("a",{href:"https://www.linkedin.com/in/shawn-shuqing-chen/",target:"_blank",children:(0,n.jsx)("img",{src:"/_next/static/media/shawn.d9ea8ac2.jpg",alt:"Image 3",className:"w-48 h-48 border-stone-200 border-x-4 border-y-4 object-cover"})}),(0,n.jsx)("a",{href:"https://www.linkedin.com/in/shawn-shuqing-chen/",target:"_blank",className:"w-10/12 mt-2 text-center",children:"Shuqing (Shawn) Chen"})]}),(0,n.jsxs)(s.E.div,{variants:e,className:"flex flex-col items-center",children:[(0,n.jsx)("a",{href:"https://www.linkedin.com/in/austin-robertson-784b18207/",target:"_blank",children:(0,n.jsx)("img",{src:"/_next/static/media/austin.05b0d5e0.jpeg",alt:"Image 3",className:"w-48 h-48 border-stone-200 border-x-4 border-y-4 object-cover"})}),(0,n.jsx)("a",{href:"https://www.linkedin.com/in/austin-robertson-784b18207/",target:"_blank",className:"w-9/12 mt-2 text-center",children:"Austin Robertson"})]})]}),(0,n.jsxs)(s.E.div,{variants:e,id:"textWrapper",className:" flex-1 w-1/2 h-full flex flex-col mt-72 px-6",children:[(0,n.jsx)(s.E.div,{variants:e,className:"text-6xl p-2 font-bold",children:"The Model"}),(0,n.jsxs)(s.E.div,{variants:e,className:"text-lg p-2 pb-8 text-justify",children:["This neural network model is based on EfficientNetB3, comprising 11,184,179 parameters (approximately 42.66 MB). It's designed for image classification with 256x256x3 input images. The model includes a Batch Normalization layer, a Dense layer with 256 neurons, dropout for regularization, and an output layer with 4 classes. While leveraging a pre-trained model like EfficientNetB3 boosts performance, it presents challenges such as high parameter count, fine-tuning complexities, memory/storage demands, and the need for substantial training data. These aspects should be considered when using this model in practice. Still we were able to reach an accuracy of 0.9925 on our testing set. We got our dataset from",(0,n.jsxs)("a",{href:"https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data.",target:"_blank",children:[" ",(0,n.jsx)("u",{children:" Kaggle"})]}),". We used the",(0,n.jsxs)("a",{href:"https://arxiv.org/abs/1905.11946",target:"_blank",children:[" ",(0,n.jsx)("u",{children:" Effecient Net V3"}),"."]})]})]})]})}}},function(e){e.O(0,[704,971,864,744],function(){return e(e.s=2950)}),_N_E=e.O()}]);